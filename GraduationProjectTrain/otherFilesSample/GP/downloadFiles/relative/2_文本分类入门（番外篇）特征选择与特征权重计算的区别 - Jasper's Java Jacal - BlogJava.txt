+1
文本分类入门（番外篇）特征选择与特征权重计算的区别 - Jasper's Java Jacal - BlogJava
 Jasper's Java Jacal 嘉士伯的Java小屋 BlogJava | 首页 | 发新随笔 | 发新文章 | 联系 | 聚合 | 管理 随笔：51 文章：2 评论：657 引用：0 文本分类入门（番外篇）特征选择与特征权重计算的区别 在文本分类的过程中，特征（也可以简单的理解为“词”）从人类能够理解的形式转换为计算机能够理解的形式时，实际上经过了两步骤的量化——特征选择阶段的重要程度量化和将具体文本转化为向量时的特征权重量化。初次接触文本分类的人很容易混淆这两个步骤使用的方法和各自的目的，因而我经常听到读者有类似“如何使用TFIDF做特征选择”或者“卡方检验量化权重后每篇文章都一样”等等困惑。 文本分类本质上也是一个模式识别的问题，因此我想借用一个更直观的例子来说说特征选择和权重量化到底各自是什么东西，当然，一旦解释清楚，你马上就会觉得文本分类这东西实在白痴，实在没什么技术含量，你也就不会再继续看我的技术博客，不过我不担心，因为你已经踏上了更光明的道路（笑），我高兴还来不及。 想想通过指纹来识别一个人的身份，只看一个人的指纹，当然说不出他姓甚名谁，识别的过程实际上是比对的过程，要与已有的指纹库比较，找出相同的，或者说相似到一定程度的那一个。 首要的问题是，人的指纹太复杂，包含太多的位置和几何形状，要完全重现一个人的指纹，存储和计算都是大麻烦。因此第一步总是一个特征选择的问题，我们把全人类的指纹都统计一下，看看哪几个位置能够最好的区分不同的人。显然不同的位置效果很不一样，在有的位置上，我的指纹是是什么形状，其他人也大都是这个形状，这个位置就不具有区分度，或者说不具有表征性，或者说，对分类问题来说，它的重要程度低。这样的位置我们就倾向于在识别的时候根本不看它，不考虑它。 那怎么看谁重要谁不重要呢？这就依赖于具体的选择方法如何来量化重要程度，对卡方检验和信息增益这类方法来说，量化以后的得分越大的特征就越重要（也就是说，有可能有些方法，是得分越小的越重要）。 比如说你看10个位置，他们的重要程度分别是：    1 2   3   4   5 6   7 8 9  10 （20，5，10，20，30，15，4，3，7， 3） 显然第1，第3，4，5，6个位置比其他位置更重要，而相对的，第1个位置又比第3个位置更重要。 识别时，我们只在那些重要的位置上采样。当今的指纹识别系统，大都只用到人指纹的5个位置（惊讶么？只要5个位置的信息就可以区分60亿人），这5个位置就是经过特征选择过程而得以保留的系统特征集合。假设这个就是刚才的例子，那么该集合应该是： （第1个位置，第3个位置，第4个位置，第5个位置，第6个位置） 当然，具体的第3个位置是指纹中的哪个位置你自己总得清楚。 确定了这5个位置之后，就可以把一个人的指纹映射到这个只有5个维度的空间中，我们就把他在5个位置上的几何形状分别转换成一个具体的值，这就是特征权重的计算。依据什么来转换，就是你选择的特征权重量化方法，在文本分类中，最常用的就是TFIDF。 我想一定是“权重“这个词误导了所有人，让大家以为TFIDF计算出的值代表的是特征的重要程度，其实完全不是。例如我们有一位男同学，他的指纹向量是： （10，3，4，20，5） 你注意到他第1个位置的得分（10）比第3个位置的得分（3）高，那么能说第1个位置比第3个位置重要么？如果再有一位女同学，她的指纹向量是： （10，20，4，20，5） 看看，第1个位置得分（10）又比第3个位置（20）低了，那这两个位置到底哪个更重要呢？答案是第1个位置更重要，但这不是在特征权重计算这一步体现出来的，而是在我们特征选择的时候就确定了，第1个位置比第3个位置更重要。 因此要记住，通过TFIDF计算一个特征的权重时，该权重体现出的根本不是特征的重要程度！ 那它代表什么？再看看两位同学的指纹，放到一起： （10， 3，4，20，5） （10，20，4，20，5） 在第三个位置上女同学的权重高于男同学，这不代表该女同学在指纹的这个位置上更“优秀“（毕竟，指纹还有什么优秀不优秀的分别么，笑），也不代表她的这个位置比男同学的这个位置更重要，3和20这两个得分，仅仅代表他们的”不同“。 在文本分类中也是如此，比如我们的系统特征集合只有两个词： （经济，发展） 这两个词是使用卡方检验（特征选择）选出来的，有一篇文章的向量形式是 （2，5） 另一篇 （3，4） 这两个向量形式就是用TFIDF算出来的，很容易看出两篇文章不是同一篇，为什么？因为他们的特征权重根本不一样，所以说权重代表的是差别，而不是优劣。想想你说“经济这个词在第二篇文章中得分高，因此它在第二篇文章中比在第一篇文章中更重要“，这句话代表什么意义呢？你自己都不知道吧（笑）。 所以，当再说起使用TFIDF来计算特征权重时，最好把“权重“这个字眼忘掉，我们就把它说成计算得分好了（甚至”得分“也不太好，因为人总会不自觉的认为，得分高的就更重要），或者就仅仅说成是量化。 如此，你就再也不会拿TFIDF去做特征选择了。 小Tips：为什么有的论文里确实使用了TFIDF作特征选择呢？ 严格说来并不是不可以，而且严格说来只要有一种方法能够从一堆特征中挑出少数的一些，它就可以叫做一种特征选择方法，就连“随机选取一部分“都算是一种，而且效果并没有差到惊人的地步哦！还是可以分对一大半的哦！所以有的人就用TFIDF的得分来把特征排排序，取得分最大的几个进入系统特征集合，效果也还行（毕竟，连随机选取效果也都还行），怎么说呢，他们愿意这么干就这么干吧。就像咱国家非得实行户口制度，这个制度说不出任何道理，也不见他带来任何好处，但不也没影响二十一世纪成为中国的世纪么，呵呵。 发表于 2009-04-19 11:40 Jasper 阅读(20231) 评论(41)  编辑  收藏 所属分类: 文本分类技术   评论 # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 效率果然很高，谢谢～ 拿TFIDF做选择的还真的不少喔，看到这样的论文马上就扔掉了。 实验中TFIDF和词频做SVM的输入区别大不？ Lebee_leon 评论于 2009-04-19 12:47  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 好文章 bee 评论于 2009-04-21 11:06  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 读完舒坦。。。 多谢博主。 博主能不能讲讲关于LIBSVM的使用方面的文章啊。。。也许如何使用本身并不难，但没人给你引个路，想开始还真难啊。。。不是有句话叫万事开头难吗？ 比如输入的文本格式要怎么处理成标准输入格式呢？还有具体使用过程中会遇到的一些问题。。。 不管怎么样，还是很期待你的下一篇文章^.^。学到了很多东西啊。 bee 评论于 2009-04-21 11:23  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 这是我曾今犯的错，呵呵，楼主的文章深入浅出，非常好，我的毕设终于顺利完成了！ sunshang 评论于 2009-04-22 22:04  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 请问楼主知道 如果我要计算多个属性和起来的 信息增益 如何去做呢？ koala++ 评论于 2009-04-25 18:09  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @koala++ 如果假设各个特征项是独立的，可以简单的计算每个特征的增益，然后取和。 如果假设不是独立的，就把他们的组合看成是一个新的变量，统计这个新变量可能的取值，每个取值取到的概率，重复运用信息增益的公式计算即可。 Jasper 评论于 2009-04-26 12:25  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 楼主，我感觉你这里的比较有问题： 你说：“我想一定是“权重“这个词误导了所有人，让大家以为TFIDF计算出的值代表的是特征的重要程度，其实完全不是。例如我们有一位男同学，他的指纹向量是：（10，3，4，20，5）你注意到他第1个位置的得分（10）比第3个位置的得分（3）高，那么能说第1个位置比第3个位置重要么？” 我想在指纹识别中这个值确实不能够说位置1就比位置3重要，那是因为你的这个从指纹特征往这个向量值映射的函数我们未知所造成的。可是在TC问题中，TFIDF值的建模就是把那些出现频率高，且区分作用大的词赋予更高的tfidf值，所以他的高是可以说明这个词更加重要的（或者是这个特征更加重要） 假如一篇文章的tfidf向量表示为（10，3，4，20，5），那么这里的“10”和“3”会带来什么效果呢？很明显，在做向量乘法计算相似度的时候显然是“10”比“3”对于整体的相似度贡献更大。因为similarity = (10，3，4，20，5) * (x1,x2,x3,x4,x5)T; 那么在不考虑x1,x2,..x5的情况下。显然10比3“贡献”大啊。 所以请博主在考虑一下，TFIDF这个在IR中如此经典的一个模型难道就真的这么一文不值？ lianghao.lee 评论于 2009-04-26 13:37  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @lianghao.lee 就是因为不同的人在分类的不同阶段对“重要”的定义彼此不同，所以大家会在一项指标重要还是不重要上存在分歧。注意我在谈特征选择阶段特征对类别区分度方面的“重要”，而您纠结在文章向量表示时相似度判别时的“重要”。这种混淆很常见，所以也不能怪您，如果您有兴趣继续在文本分类方面深入，相信您有一天会得到不同的理解。 Jasper 评论于 2009-04-26 17:07  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 非常感谢 koala++ 评论于 2009-04-27 09:48  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 我曾经也在这个问题上琢磨了好久。现在很多文章都没有在这点上说清楚，也许是我没能理解清楚。 呵呵 有这篇文章，以后一定能让好多人解惑。 James 评论于 2009-04-28 14:13  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @Jasper 呵呵~ 我并没有说TFIDF是最好的特征选择方法，可他确实是一种特征选择的途径，我只是不太同意你在最后说的： “所以有的人就用TFIDF的得分来把特征排排序，取得分最大的几个进入系统特征集合，效果也还行（毕竟，连随机选取效果也都还行）” 因为如果您能够通过实验证明统计结果表明TFIDF特征选择与随机选取效果的期望和方差基本一致的话，您就可以说明TFIDF确实对特征提取没有作用，而其他人之前确实将TFIDF与特征选择混淆了。可是如果他的效果好于随机的话就说明他还是有一定的道理的。 呵呵~ 还有你说：而您纠结在文章向量表示时相似度判别时的“重要”。 特征提取不是分类的目的，只是想通过特征提取来降维并得到有区分度的特征词，可是这些特征词最后还是为基于相似度的分类服务的，所以可以将特征提取的作用归纳为:找到区分度重要的词，找到对相似度计算重要的词 对于区分度重要，如果通过Tfidf提取出来的特征能够很好的定义相同类别里面文本的相似，不就是能够很好的定义不同类别里面文本的区别吗？也许是博主认为做tfidf特征提取就是将tfidf值最高的词提取出来了，所以认为这样的不合理吧。如果能够很好的利用tfidf值的类内分布和类间分布来做特征提取是能够很好的得到有区分度的特征词的。 而另一方面，而正如博主所说的tfidf在相似度计算中是很“重要”的，所以用tfidf来做特征提取对于之后的分类的相似度计算是很有用的。 拙见，海涵~ lianghao.lee 评论于 2009-05-01 21:32  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @lianghao.lee 连您自己都同意了我的观点，即认为单纯使用TFIDF值来判断一个特征是否有区分度不够，而应该考虑该值在类间的分布，这个分布情况，不管您给它起什么名字，它一定不叫TFIDF，它只是以TFIDF值为基础，正如信息增益，卡方检验和互信息等方法全都是以特征的文档频率为基础一样，它们都不叫文档频率方法，只有直接依据文档频率大小排序的方法才叫做“文档频率特征选择”（而且确实有这种方法）。因为说到底，我们从文本中能观察到的量其实只有两个：词频和文档频率，所有的方法一律以这两个量为计算基础，但不能由此把所有的方法都叫做词频方法或者文档频率方法。TFIDF也是一种很基础的量（它是由词频和文档频率计算来的），同样它也带来了较词频和文档频率单独使用完全不同的效果。 如果您同意这些，您就会明白我所说的“TFIDF不能用来做特征选择”，正是指单独使用一个特征的TFIDF值来判断毫无道理，卡方检验完全基于文档频率计算，但单看文档频率也毫无道理（好吧，文档频率有那么一点道理，呵呵）。 另外，两个文档的相似度在有的分类模型里（例如支持向量机）里完全没有用处，您通过文档在空间中的分布也可以看出来，一些位于类别边界附近的文档，其实与另一个类里的文档更加相似（反而与同类的文档不那么相似），在这种模型中，我们仅通过它所处的位置来判断分类，而丝毫不受它与谁相似的影响。相信这一点您一想就能明白。当然这里所争论的乃是对分类来说文档相似度是否一定有用（对有的方法完全没用），而不是说TFIDF对判断相似是否有用，我要说，对文档相似度计算来说，TFIDF是非常有效的。 Jasper 评论于 2009-05-02 16:47  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 如果说权重不是重要度，那用KNN法的时候，那些权重大的的确起到了比较大的影响作用。 dvdface 评论于 2009-05-02 22:00  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 特征选择是降维，减少文本特征的数量，去掉冗余信息量。特征权重计算的权重只是为了向量表示吗？对后面的文本分类算法起到什么作用了？ radar 评论于 2009-06-05 16:47  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @radar 准确的说,计算权重是为了能给每篇文章一个"唯一"的身份,就跟计算指纹不是为了得到指纹数据本身,而是为了得到唯一性一样.我们需要一种指标,这种指标能让计算机"看到"不同的两篇文章确实不同,并且知道不同在哪里.只有能看到这种不同,计算机才能看出同类文章相似在哪里.如果有一种指标,它衡量每篇文章时结果都一样,显然程序没法在这种数据基础上学习分类的.因此形成向量表示实际是一个中间目的,终极的目的是为了让文章之间看上去彼此不同,并且这种不同有所依据. Jasper 评论于 2009-06-05 16:56  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 想请问一下，那新的待分类的文本的权重如何确定？也是和训练文本一样？重新TFIDF来计算？ hezi 评论于 2009-06-14 09:58  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 博主，能不能写下关于SMO算法啊，详细通俗易懂点的，谢谢 dawsonjin 评论于 2009-07-03 20:29  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 看百家讲坛，喜欢易中天把三国讲得轻松；今天看你的SVM入门（七），吸引我一路看过来。了不起，了不起。复杂概念在你这儿变得这么容易亲近，榜样啊。 正学模式分类 评论于 2009-09-16 20:56  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 您的意思，是不是类似于，中国的劳动密集型的制造业发达，美国的技术密集型的科技产业发达，这样形成互补，但是中国跟印度，都是劳动密集型的制造业发达，有类似的条件，应该归为一类。但是，中国的劳动密集型的制造业在中国，“不重要”。重要不重要，看你怎么比吧！难道说跟俄罗斯的轻工业来比，体现中国轻工业占了很高的GDP比重？很“重要”？只能说它在中国比在俄罗斯占的GDP比重大，更重要。（看它不当轻工当回事，中国倒是合理发展了轻工） 一个固定的词IDF只有一个，不同的是TF，占词频的比重大。在AB两篇文章中如果几个不同的词，TF都基本一致，比如说都是（5，1），而这两个词在C中是（1，5），难道就仅靠随机判断，就能得出AB同一类，跟C不同一类吗？svm里面的核方法，是在原空间进行点积或者向量相减之后点积（rbf核）这样的方法可以跟随机等价吗？ 还有“经济这个词在第二篇文章中得分高，因此它在第二篇文章中比在第一篇文章中更重要”，TF高，难道意味着这个词在第二篇文章不比第一篇重要吗？ eric 评论于 2009-10-05 00:58  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 第二段“占词频的比重大”，后面补上“的词基本一致，难道还不能分为一类吗？” eric 评论于 2009-10-05 01:05  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 如果要谈什么重要还是不重要,那首先要牢记评判重要的标准,或者说,明确自己说的指标针对什么问题而言重要还是不重要。文中的观点是告诉大家TFIDF在特征选择阶段不重要，而在分类阶段很重要。但有太多的朋友在辩驳时混淆了问题的讨论范围。您也一再强调TFIDF值一样的词对分类的影响云云，可见您其实也在用我的结论往另一个问题上套。不过学习的过程大抵如此，我们一错再错，一错再错，但却越来越好，越来越好。希望能和大家一起进步。@eric Jasper 评论于 2009-10-05 14:44  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 在利用wvtool实现文本的向量化时候， 似乎看不到特征选取，即上文中的选择特征位置的过程， 而仅仅存在TFIDF来进行对关键词（针对词频选取topN作为关键词）进行向量化。 如何将博主提到的卡方检验和chi融入其中呢？ cuijie 评论于 2009-10-26 16:50  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @cuijie 我也有这个问题，还希望有人能给解答下 strayly 评论于 2009-12-26 18:13  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 可以理解为:特征选择，如chi-square之类比较的是特征之间谁对分类效果更优，属于横向比对；而tfidf，比较的是单个特征对于文档应当归属那个类的权重，属于纵向比对. l0he1g 评论于 2010-03-11 10:48  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @Jasper同意 char 评论于 2010-12-09 10:39  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 看完楼主的文章有个疑问：我一直觉得TFIDF用来做特征选择依据挺正常的啊？为什么楼主觉得这样不合理呢？ TFIDF= 某个词在某篇文本中出现的次数 / 有该词出现的文本数量， 我觉得这个TFIDF值能够反映某个词对于不同类文本间的区分度，所以TFIDF越大就证明这个词对于区分不同类文本的作用越大（也就意味着特征明显）。 不知我说的对不对？ 请教楼主，谢谢~ Andyseren 评论于 2010-12-27 16:17  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 看了很有收获 guolinagogo 评论于 2011-02-25 16:12  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 博主知道RVM吗？还想听下博主关于RVM的讲解。 happy 评论于 2011-04-08 09:35  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 博主的思路应该是局限与discriminative model 里面，做为分类买的一种，tfidf确实不太适合，但是生成模型里，面有时候就是有权重的概念@lianghao.lee alexz 评论于 2012-09-02 00:24  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 看了博主的观点，有点疑问，对于一篇待分类文本，如果不用tfidf，那么应该如何进行特征提取？ 路过 评论于 2012-10-19 17:50  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 具体用SVM如何做，楼主能不能给个文章或者链接？ 刘康 评论于 2012-10-27 16:47  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 @Jasper "即认为单纯使用TFIDF值来判断一个特征是否有区分度不够，而应该考虑该值在类间的分布，这个分布情况，不管您给它起什么名字，它一定不叫TFIDF，它只是以TFIDF值为基础" “该值在类间的分布”即是说该选择的特征应该在某类出现多，而其它类出现少。对吧？也即该特征的IDF（反文档频率）在不同类的方差越大越好。 那么，在选特征时需满足两个条件： 1.特征的TFIDF够高，保证文档区分度 2.特征的IDF在不同类的方差够大，保证分类的区分度 不知这样如何，请指教 YCloud 评论于 2012-11-06 15:22  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 同意，博主文章对看不懂那些所谓论文的人帮助很大~我也是其中之一~~ 阿D 评论于 2012-11-23 17:40  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 能对但一个文件进行每个特征的权重计算吗~？ 阿D 评论于 2012-12-21 15:57  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 只对一篇文档进行特征权重量化的话怎么能用ＴＦＩＤＦ　文本总数是１　某个词的文件频率就会是１　这样ＩＤＦ值就为０　那么提取出来的特征向量就是个零向量了！ ｚｗｂｊａｙ 评论于 2012-12-23 11:32  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 那如果经过量化之后的数值是相同的，比如你举例的男生和女生的五维数值相同，则说明以下两点中一个吗？1，俩人是一个人；2，权重计算存在的漏洞，或者特征选择的不够好。 Angie 评论于 2013-08-10 15:23  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 同意，tf-idf能有效评估词对单一一个文档的重要性，但是无法评估词对某个类别的重要程度@l0he1g te_amo_cuba 评论于 2013-08-27 17:05  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 狠好，收藏~ talisa 评论于 2014-03-24 16:02  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 深入浅出啊，可惜作者没有更新了！ 天马行空 评论于 2014-04-06 09:29  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别 赞同楼主！ 很多人没有搞清楚特征选选择和特征量化的区别。 idf用来做特征选择是可以的，因为它代表该词（特征）在文档集上的分布；tfidf则不能用于特征选择，因为特征选择的目的是在所有词中选择一部分重要的词作为文本特征，判断标准是跟具体某一篇文档无关的，而tfidf的tf因子与文档有关。在不同文档中tf不同，因此tfidf只能区分该词对不同文档的重要程度，但不能代表分类问题的区分度。 tfidf作为特征量化方法是可以，实际上在选择了特征后用tf也可以，因为同一个词idf对不同文档来说是常量，“特征量化”本身一定要能差别话该特征在不同文档上的分布。 karl 评论于 2014-06-04 13:14  回复  更多评论     # re: 文本分类入门（番外篇）特征选择与特征权重计算的区别[未登录] 能不能加我QQ?524857559，我叫LQ LQ 评论于 2014-10-15 18:25  回复  更多评论       新用户注册  刷新评论列表   找优秀程序员，就在博客园 标题 请输入标题 姓名 请输入你的姓名 主页 请输入验证码 验证码 *   内容(请不要发表任何与政治相关的内容) 请输入评论内容 Remember Me?   登录       [使用Ctrl+Enter键可以直接提交] 网站导航: 博客园   IT新闻   知识库   C++博客   程序员招聘   管理 相关文章: 文本分类入门（番外篇）特征选择与特征权重计算的区别 SVM入门（十）将SVM用于多类分类 文本分类入门（十一）特征选择方法之信息增益 SVM入门（九）松弛变量（续） SVM入门（八）松弛变量 SVM入门（七）为何需要核函数 SVM入门（六）线性分类器的求解——问题的转化，直观角度 SVM入门（五）线性分类器的求解——问题的描述Part2 SVM入门（四）线性分类器的求解——问题的描述Part1 SVM入门（一）至（三）Refresh   < 2009年4月 > 日 一 二 三 四 五 六 29 30 31 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 1 2 3 4 5 6 7 8 9 公告 邮箱：zhenandaci@msn.com 常用链接 我的随笔 我的文章 我的评论 我的参与 最新评论 留言簿(58) 给我留言 查看公开留言 查看私人留言 随笔分类 Java技术(10) (rss) Web技术(1) (rss) 书评 (rss) 技术观点 (rss) 文本分类技术(36) (rss) 桌面技术(6) (rss) 牢骚(2) (rss) 设计(2) (rss) 随笔档案 2009年5月 (1) 2009年4月 (2) 2009年3月 (6) 2009年2月 (10) 2009年1月 (3) 2008年12月 (6) 2008年11月 (4) 2008年10月 (2) 2008年9月 (2) 2008年8月 (1) 2008年7月 (2) 2008年6月 (9) 2008年5月 (4) 文章分类 Java Tech (rss) Search Engine (rss) Text Categorization (rss) 人文社科 (rss) 搜索   最新评论 1. re: 文本分类入门（十）特征选择算法之开方检验 @yichu 你说得对 --yichu 2. re: 文本分类入门（十）特征选择算法之开方检验 @yichu D11为 篮球&体育 的相关性；D12为 篮球&非体育 的相关性；...;以此类推。 --yichu 3. re: 文本分类入门（十）特征选择算法之开方检验 D12，D21，D22 它们分别是什么呢？ --yichu 4. re: 文本分类入门（十）特征选择算法之开方检验 不是应该叫 卡方检验 chi-square test 么 --yichu 5. re: SVM入门（七）为何需要核函数 也得好！ --STUPID Learner 阅读排行榜 1. SVM入门（一）至（三）Refresh(83038) 2. SVM入门（七）为何需要核函数(43025) 3. SVM入门（十）将SVM用于多类分类(35082) 4. 文本分类入门（十一）特征选择方法之信息增益(26917) 5. SVM入门（四）线性分类器的求解——问题的描述Part1(24763) 评论排行榜 1. SVM入门（一）至（三）Refresh(99) 2. SVM入门（十）将SVM用于多类分类(58) 3. 文本分类入门（十一）特征选择方法之信息增益(58) 4. 10分钟开始使用ICTCLAS Java版(54) 5. SVM入门（七）为何需要核函数(52) Powered by: 博客园 模板提供：沪江博客 Copyright ©2015 Jasper
